{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread, imwrite\n",
    "\n",
    "from fcn import VGGNet, FCNs\n",
    "from dataset import SegmentationDataset, LabelToOnehot, imshow\n",
    "from train import train_model, visualize_model\n",
    "\n",
    "from horsetools import list_files\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find normalization constants for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find means and stds of dataset\n",
    "imgs_list = list_files('stroma_epithelia/images')\n",
    "np_means = np.zeros((len(imgs_list), 3))\n",
    "np_stds = np.zeros_like(np_means)\n",
    "for i, img_name in enumerate(imgs_list):\n",
    "    img = imread(img_name)\n",
    "    np_means[i] = np.mean(img, axis=(0, 1))\n",
    "    np_stds[i] = np.std(img, axis=(0, 1))\n",
    "    \n",
    "channel_means = np.mean(np_means, axis=0)\n",
    "channel_stds = np.std(np_stds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Means: {}'.format(channel_means))\n",
    "print('Stds: {}'.format(channel_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_means = (164.60564156, 150.75147313, 178.36823845)\n",
    "channel_stds = (9.46653235, 16.23701039, 9.48000306)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = 'stroma_epithelia'\n",
    "crop_size = 224\n",
    "labels = (0, 1, 2)\n",
    "dataset_phases = ['train']\n",
    "\n",
    "n_labels = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': {\n",
    "        'imgs': transforms.Compose([\n",
    "            transforms.CenterCrop(crop_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(channel_means, channel_stds)\n",
    "        ]),\n",
    "        'masks': transforms.Compose([\n",
    "            transforms.CenterCrop(crop_size),\n",
    "            LabelToOnehot(labels),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    }\n",
    "}\n",
    "\n",
    "image_datasets = {x: SegmentationDataset(data_root, labels, \n",
    "                                         image_transforms=data_transforms[x]['imgs'],\n",
    "                                         mask_transforms=data_transforms[x]['masks'])\n",
    "                  for x in dataset_phases}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=4, \n",
    "                             shuffle=True, num_workers=4)\n",
    "               for x in dataset_phases}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in dataset_phases}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare label and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_name = 'stroma_epithelia/masks/0.1_110_2_1.png'\n",
    "mask = imread(mask_name)\n",
    "LO = LabelToOnehot(labels)\n",
    "mask_oh = LO(mask)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(mask)\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "print('Image shape: {}'.format(inputs.shape))\n",
    "print('Masks shape: {}'.format(masks.shape))\n",
    "imshow(torchvision.utils.make_grid(inputs), means=channel_means, stds=channel_stds)\n",
    "imshow(torchvision.utils.make_grid(masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.001\n",
    "momentum = 0.9\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
    "fcn_model = FCNs(pretrained_net=vgg_model, n_class=n_labels)\n",
    "\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(fcn_model.parameters(), lr=learn_rate, momentum=momentum)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = train_model(fcn_model, dataloaders, criterion, optimizer_ft, scheduler, \n",
    "                        dataset_phases, dataset_sizes, device=device, num_epochs=25)\n",
    "visualize_model(fcn_model, dataloaders, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PyTorchSIIM]",
   "language": "python",
   "name": "conda-env-PyTorchSIIM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
